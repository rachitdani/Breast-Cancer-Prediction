{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39f38a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d222f0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890       0  \n",
       "1          0.2750                  0.08902       0  \n",
       "2          0.3613                  0.08758       0  \n",
       "3          0.6638                  0.17300       0  \n",
       "4          0.2364                  0.07678       0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"datasets/breast_cancer_dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be911c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Independent and dependent features\n",
    "X = df.drop(labels=['target'],axis=1)\n",
    "y = df[['target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1238c591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     target\n",
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "..      ...\n",
       "564       0\n",
       "565       0\n",
       "566       0\n",
       "567       0\n",
       "568       1\n",
       "\n",
       "[569 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9936a613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define which columns should be should be scaled\n",
    "# Here all are numerical columns \n",
    "numerical_cols = X.select_dtypes(exclude='object').columns\n",
    "categorical_cols = X.select_dtypes(include='object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "027c4e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer ## HAndling Missing Values\n",
    "from sklearn.preprocessing import StandardScaler # HAndling Feature Scaling\n",
    "from sklearn.preprocessing import OrdinalEncoder # Ordinal Encoding\n",
    "## pipelines\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74c2eacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Numerical Pipeline\n",
    "num_pipeline=Pipeline(\n",
    "    steps=[\n",
    "    ('imputer',SimpleImputer(strategy='median')),\n",
    "    ('scaler',StandardScaler())\n",
    "\n",
    "    ]\n",
    "\n",
    ")\n",
    "\n",
    "# Categorigal Pipeline\n",
    "cat_pipeline=Pipeline(\n",
    "    steps=[\n",
    "    ('imputer',SimpleImputer(strategy='most_frequent')),\n",
    "    ('scaler',StandardScaler())\n",
    "    ]\n",
    "\n",
    ")\n",
    "\n",
    "preprocessor=ColumnTransformer([\n",
    "('num_pipeline',num_pipeline,numerical_cols),\n",
    "('cat_pipeline',cat_pipeline,categorical_cols)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3dd98381",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train test split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f91c6261",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=pd.DataFrame(preprocessor.fit_transform(X_train),columns=preprocessor.get_feature_names_out())\n",
    "X_test=pd.DataFrame(preprocessor.transform(X_test),columns=preprocessor.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "311ef18a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_pipeline__mean radius</th>\n",
       "      <th>num_pipeline__mean texture</th>\n",
       "      <th>num_pipeline__mean perimeter</th>\n",
       "      <th>num_pipeline__mean area</th>\n",
       "      <th>num_pipeline__mean smoothness</th>\n",
       "      <th>num_pipeline__mean compactness</th>\n",
       "      <th>num_pipeline__mean concavity</th>\n",
       "      <th>num_pipeline__mean concave points</th>\n",
       "      <th>num_pipeline__mean symmetry</th>\n",
       "      <th>num_pipeline__mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>num_pipeline__worst radius</th>\n",
       "      <th>num_pipeline__worst texture</th>\n",
       "      <th>num_pipeline__worst perimeter</th>\n",
       "      <th>num_pipeline__worst area</th>\n",
       "      <th>num_pipeline__worst smoothness</th>\n",
       "      <th>num_pipeline__worst compactness</th>\n",
       "      <th>num_pipeline__worst concavity</th>\n",
       "      <th>num_pipeline__worst concave points</th>\n",
       "      <th>num_pipeline__worst symmetry</th>\n",
       "      <th>num_pipeline__worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.259330</td>\n",
       "      <td>2.439012</td>\n",
       "      <td>0.172382</td>\n",
       "      <td>0.156133</td>\n",
       "      <td>-0.909507</td>\n",
       "      <td>-1.090974</td>\n",
       "      <td>-0.506455</td>\n",
       "      <td>-0.541377</td>\n",
       "      <td>0.128087</td>\n",
       "      <td>-1.370350</td>\n",
       "      <td>...</td>\n",
       "      <td>0.180986</td>\n",
       "      <td>1.837433</td>\n",
       "      <td>0.061595</td>\n",
       "      <td>0.065562</td>\n",
       "      <td>-0.743905</td>\n",
       "      <td>-0.990479</td>\n",
       "      <td>-0.547035</td>\n",
       "      <td>-0.733436</td>\n",
       "      <td>0.491065</td>\n",
       "      <td>-1.251415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.764239</td>\n",
       "      <td>0.363084</td>\n",
       "      <td>1.824839</td>\n",
       "      <td>1.772202</td>\n",
       "      <td>0.587236</td>\n",
       "      <td>1.301367</td>\n",
       "      <td>1.478879</td>\n",
       "      <td>2.097370</td>\n",
       "      <td>1.119787</td>\n",
       "      <td>-0.022417</td>\n",
       "      <td>...</td>\n",
       "      <td>1.609000</td>\n",
       "      <td>-0.032638</td>\n",
       "      <td>1.521502</td>\n",
       "      <td>1.560719</td>\n",
       "      <td>-0.207337</td>\n",
       "      <td>0.382917</td>\n",
       "      <td>0.841350</td>\n",
       "      <td>1.540941</td>\n",
       "      <td>0.246979</td>\n",
       "      <td>-0.441615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.859073</td>\n",
       "      <td>0.657657</td>\n",
       "      <td>0.883795</td>\n",
       "      <td>0.783064</td>\n",
       "      <td>-0.434606</td>\n",
       "      <td>0.429383</td>\n",
       "      <td>0.109018</td>\n",
       "      <td>0.659037</td>\n",
       "      <td>1.051269</td>\n",
       "      <td>-1.130905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.815884</td>\n",
       "      <td>0.255317</td>\n",
       "      <td>0.871683</td>\n",
       "      <td>0.685023</td>\n",
       "      <td>-0.806505</td>\n",
       "      <td>0.211594</td>\n",
       "      <td>-0.185747</td>\n",
       "      <td>0.594873</td>\n",
       "      <td>0.231333</td>\n",
       "      <td>-0.490641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.904058</td>\n",
       "      <td>-0.163436</td>\n",
       "      <td>-0.886091</td>\n",
       "      <td>-0.803622</td>\n",
       "      <td>0.293482</td>\n",
       "      <td>-0.556744</td>\n",
       "      <td>-0.474767</td>\n",
       "      <td>-0.492787</td>\n",
       "      <td>-1.191775</td>\n",
       "      <td>0.490276</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.804831</td>\n",
       "      <td>-0.016277</td>\n",
       "      <td>-0.735089</td>\n",
       "      <td>-0.716432</td>\n",
       "      <td>0.217445</td>\n",
       "      <td>-0.570226</td>\n",
       "      <td>-0.611980</td>\n",
       "      <td>-0.533236</td>\n",
       "      <td>-1.045420</td>\n",
       "      <td>-0.347600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.190476</td>\n",
       "      <td>-0.093851</td>\n",
       "      <td>-0.173874</td>\n",
       "      <td>-0.287084</td>\n",
       "      <td>0.678159</td>\n",
       "      <td>0.193611</td>\n",
       "      <td>-0.028177</td>\n",
       "      <td>0.123785</td>\n",
       "      <td>-0.037797</td>\n",
       "      <td>-0.264679</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.318008</td>\n",
       "      <td>0.248773</td>\n",
       "      <td>-0.310521</td>\n",
       "      <td>-0.370923</td>\n",
       "      <td>0.508086</td>\n",
       "      <td>0.021733</td>\n",
       "      <td>0.362679</td>\n",
       "      <td>0.480429</td>\n",
       "      <td>-0.396091</td>\n",
       "      <td>-0.374132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_pipeline__mean radius  num_pipeline__mean texture  \\\n",
       "0                   0.259330                    2.439012   \n",
       "1                   1.764239                    0.363084   \n",
       "2                   0.859073                    0.657657   \n",
       "3                  -0.904058                   -0.163436   \n",
       "4                  -0.190476                   -0.093851   \n",
       "\n",
       "   num_pipeline__mean perimeter  num_pipeline__mean area  \\\n",
       "0                      0.172382                 0.156133   \n",
       "1                      1.824839                 1.772202   \n",
       "2                      0.883795                 0.783064   \n",
       "3                     -0.886091                -0.803622   \n",
       "4                     -0.173874                -0.287084   \n",
       "\n",
       "   num_pipeline__mean smoothness  num_pipeline__mean compactness  \\\n",
       "0                      -0.909507                       -1.090974   \n",
       "1                       0.587236                        1.301367   \n",
       "2                      -0.434606                        0.429383   \n",
       "3                       0.293482                       -0.556744   \n",
       "4                       0.678159                        0.193611   \n",
       "\n",
       "   num_pipeline__mean concavity  num_pipeline__mean concave points  \\\n",
       "0                     -0.506455                          -0.541377   \n",
       "1                      1.478879                           2.097370   \n",
       "2                      0.109018                           0.659037   \n",
       "3                     -0.474767                          -0.492787   \n",
       "4                     -0.028177                           0.123785   \n",
       "\n",
       "   num_pipeline__mean symmetry  num_pipeline__mean fractal dimension  ...  \\\n",
       "0                     0.128087                             -1.370350  ...   \n",
       "1                     1.119787                             -0.022417  ...   \n",
       "2                     1.051269                             -1.130905  ...   \n",
       "3                    -1.191775                              0.490276  ...   \n",
       "4                    -0.037797                             -0.264679  ...   \n",
       "\n",
       "   num_pipeline__worst radius  num_pipeline__worst texture  \\\n",
       "0                    0.180986                     1.837433   \n",
       "1                    1.609000                    -0.032638   \n",
       "2                    0.815884                     0.255317   \n",
       "3                   -0.804831                    -0.016277   \n",
       "4                   -0.318008                     0.248773   \n",
       "\n",
       "   num_pipeline__worst perimeter  num_pipeline__worst area  \\\n",
       "0                       0.061595                  0.065562   \n",
       "1                       1.521502                  1.560719   \n",
       "2                       0.871683                  0.685023   \n",
       "3                      -0.735089                 -0.716432   \n",
       "4                      -0.310521                 -0.370923   \n",
       "\n",
       "   num_pipeline__worst smoothness  num_pipeline__worst compactness  \\\n",
       "0                       -0.743905                        -0.990479   \n",
       "1                       -0.207337                         0.382917   \n",
       "2                       -0.806505                         0.211594   \n",
       "3                        0.217445                        -0.570226   \n",
       "4                        0.508086                         0.021733   \n",
       "\n",
       "   num_pipeline__worst concavity  num_pipeline__worst concave points  \\\n",
       "0                      -0.547035                           -0.733436   \n",
       "1                       0.841350                            1.540941   \n",
       "2                      -0.185747                            0.594873   \n",
       "3                      -0.611980                           -0.533236   \n",
       "4                       0.362679                            0.480429   \n",
       "\n",
       "   num_pipeline__worst symmetry  num_pipeline__worst fractal dimension  \n",
       "0                      0.491065                              -1.251415  \n",
       "1                      0.246979                              -0.441615  \n",
       "2                      0.231333                              -0.490641  \n",
       "3                     -1.045420                              -0.347600  \n",
       "4                     -0.396091                              -0.374132  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2230a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model Training\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a89b1857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression = LogisticRegression()\n",
    "regression.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e96a253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(true, predicted):\n",
    "    accuracy = accuracy_score(true, predicted)\n",
    "    confusionmat = confusion_matrix(true, predicted)\n",
    "    report = classification_report(true, predicted)\n",
    "    return accuracy,confusionmat,report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06819c8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = regression.predict(X_test)\n",
    "accuracyy,confusionmatt,reportt = evaluate_model(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e482f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Training Performance\n",
      "\n",
      "Confusion Matrix:\n",
      " [[52  1]\n",
      " [ 0 90]]\n",
      "\n",
      "Classification Report: \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        53\n",
      "           1       0.99      1.00      0.99        90\n",
      "\n",
      "    accuracy                           0.99       143\n",
      "   macro avg       0.99      0.99      0.99       143\n",
      "weighted avg       0.99      0.99      0.99       143\n",
      "\n",
      "\n",
      "Accuracy: 0.993006993006993\n"
     ]
    }
   ],
   "source": [
    "print('Model Training Performance')\n",
    "print(\"\\nConfusion Matrix:\\n\",confusionmatt)\n",
    "print(\"\\nClassification Report: \\n\\n\",reportt)\n",
    "print(\"\\nAccuracy:\",accuracyy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "900e4270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "\n",
      "Confusion Matrix:\n",
      " [[52  1]\n",
      " [ 0 90]]\n",
      "\n",
      "Classification Report: \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        53\n",
      "           1       0.99      1.00      0.99        90\n",
      "\n",
      "    accuracy                           0.99       143\n",
      "   macro avg       0.99      0.99      0.99       143\n",
      "weighted avg       0.99      0.99      0.99       143\n",
      "\n",
      "\n",
      "Accuracy: 99.3006993006993\n",
      "===================================\n",
      "Support Vector Machine\n",
      "\n",
      "Confusion Matrix:\n",
      " [[52  1]\n",
      " [ 2 88]]\n",
      "\n",
      "Classification Report: \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97        53\n",
      "           1       0.99      0.98      0.98        90\n",
      "\n",
      "    accuracy                           0.98       143\n",
      "   macro avg       0.98      0.98      0.98       143\n",
      "weighted avg       0.98      0.98      0.98       143\n",
      "\n",
      "\n",
      "Accuracy: 97.9020979020979\n",
      "===================================\n",
      "Naive Bayes\n",
      "\n",
      "Confusion Matrix:\n",
      " [[47  6]\n",
      " [ 5 85]]\n",
      "\n",
      "Classification Report: \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.89      0.90        53\n",
      "           1       0.93      0.94      0.94        90\n",
      "\n",
      "    accuracy                           0.92       143\n",
      "   macro avg       0.92      0.92      0.92       143\n",
      "weighted avg       0.92      0.92      0.92       143\n",
      "\n",
      "\n",
      "Accuracy: 92.3076923076923\n",
      "===================================\n",
      "Random Forest\n",
      "\n",
      "Confusion Matrix:\n",
      " [[48  5]\n",
      " [ 3 87]]\n",
      "\n",
      "Classification Report: \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.92        53\n",
      "           1       0.95      0.97      0.96        90\n",
      "\n",
      "    accuracy                           0.94       143\n",
      "   macro avg       0.94      0.94      0.94       143\n",
      "weighted avg       0.94      0.94      0.94       143\n",
      "\n",
      "\n",
      "Accuracy: 94.4055944055944\n",
      "===================================\n",
      "Gradient Boosting\n",
      "\n",
      "Confusion Matrix:\n",
      " [[48  5]\n",
      " [ 4 86]]\n",
      "\n",
      "Classification Report: \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.91        53\n",
      "           1       0.95      0.96      0.95        90\n",
      "\n",
      "    accuracy                           0.94       143\n",
      "   macro avg       0.93      0.93      0.93       143\n",
      "weighted avg       0.94      0.94      0.94       143\n",
      "\n",
      "\n",
      "Accuracy: 93.7062937062937\n",
      "===================================\n",
      "Decision Tree\n",
      "\n",
      "Confusion Matrix:\n",
      " [[46  7]\n",
      " [ 8 82]]\n",
      "\n",
      "Classification Report: \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.87      0.86        53\n",
      "           1       0.92      0.91      0.92        90\n",
      "\n",
      "    accuracy                           0.90       143\n",
      "   macro avg       0.89      0.89      0.89       143\n",
      "weighted avg       0.90      0.90      0.90       143\n",
      "\n",
      "\n",
      "Accuracy: 89.5104895104895\n",
      "===================================\n",
      "Neural Network (MLP)\n",
      "\n",
      "Confusion Matrix:\n",
      " [[50  3]\n",
      " [ 2 88]]\n",
      "\n",
      "Classification Report: \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95        53\n",
      "           1       0.97      0.98      0.97        90\n",
      "\n",
      "    accuracy                           0.97       143\n",
      "   macro avg       0.96      0.96      0.96       143\n",
      "weighted avg       0.96      0.97      0.96       143\n",
      "\n",
      "\n",
      "Accuracy: 96.5034965034965\n",
      "===================================\n"
     ]
    }
   ],
   "source": [
    "models={\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Support Vector Machine\": SVC(kernel='linear'),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Neural Network (MLP)\": MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=1000, random_state=42)\n",
    "}\n",
    "trained_model_list=[]\n",
    "model_list=[]\n",
    "accuracy_list=[]\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "    model=list(models.values())[i]\n",
    "    model.fit(X_train,y_train)\n",
    "\n",
    "    #Make Predictions\n",
    "    y_pred=model.predict(X_test)\n",
    "\n",
    "    accuracy,confusionmat,report =evaluate_model(y_test,y_pred)\n",
    "\n",
    "    print(list(models.keys())[i])\n",
    "    model_list.append(list(models.keys())[i])\n",
    "\n",
    "    #print('Model Training Performance')\n",
    "    print(\"\\nConfusion Matrix:\\n\",confusionmat)\n",
    "    print(\"\\nClassification Report: \\n\\n\",report)\n",
    "    print(\"\\nAccuracy:\",accuracy*100)\n",
    "\n",
    "    accuracy_list.append(accuracy)\n",
    "    \n",
    "    print('='*35)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc3ee6a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Logistic Regression': 0.993006993006993,\n",
       " 'Support Vector Machine': 0.9790209790209791,\n",
       " 'Naive Bayes': 0.9230769230769231,\n",
       " 'Random Forest': 0.9440559440559441,\n",
       " 'Gradient Boosting': 0.9370629370629371,\n",
       " 'Decision Tree': 0.8951048951048951,\n",
       " 'Neural Network (MLP)': 0.965034965034965}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dict = dict(zip(model_list, accuracy_list))\n",
    "my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aaec415d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "import pickle\n",
    "\n",
    "# Find the index of the model with the highest R-squared score\n",
    "best_model_index = accuracy_list.index(max(accuracy_list))\n",
    "\n",
    "# Get the best model from the list of trained models\n",
    "best_model = list(models.values())[best_model_index]\n",
    "\n",
    "# Save the best model to a file using pickle\n",
    "with open('bestt_model.pkl', 'wb') as model_file:\n",
    "    pickle.dump(best_model, model_file)\n",
    "\n",
    "# Loading the best model\n",
    "with open('bestt_model.pkl', 'rb') as model_file:\n",
    "    loaded_model = pickle.load(model_file) \n",
    "\n",
    "'''\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8e56ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of classifiers and their respective hyperparameter grids for tuning\n",
    "classifiers = {\n",
    "    \"Logistic Regression\": {\n",
    "        \"model\": LogisticRegression(),\n",
    "        \"params\": {\n",
    "            \"penalty\": [\"l1\", \"l2\"],\n",
    "            \"C\": [0.01, 0.1, 1, 10]\n",
    "        }\n",
    "    },\n",
    "    \"Support Vector Machine\": {\n",
    "        \"model\": SVC(),\n",
    "        \"params\": {\n",
    "            \"C\": [0.1, 1, 10],\n",
    "            \"kernel\": [\"linear\", \"rbf\"]\n",
    "        }\n",
    "    },\n",
    "    \"Naive Bayes\": {\n",
    "        \"model\": GaussianNB(),\n",
    "        \"params\": {}\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        \"model\": RandomForestClassifier(),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [50, 100, 200],\n",
    "            \"max_depth\": [None, 10, 20],\n",
    "            \"min_samples_split\": [2, 5, 10],\n",
    "            \"min_samples_leaf\": [1, 2, 4]\n",
    "        }\n",
    "    },\n",
    "    \"Gradient Boosting\": {\n",
    "        \"model\": GradientBoostingClassifier(),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [50, 100, 200],\n",
    "            \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "            \"max_depth\": [3, 4, 5]\n",
    "        }\n",
    "    },\n",
    "    \"Decision Tree\": {\n",
    "        \"model\": DecisionTreeClassifier(),\n",
    "        \"params\": {\n",
    "            \"max_depth\": [None, 10, 20],\n",
    "            \"min_samples_split\": [2, 5, 10],\n",
    "            \"min_samples_leaf\": [1, 2, 4]\n",
    "        }\n",
    "    },\n",
    "    \"Neural Network (MLP)\": {\n",
    "        \"model\": MLPClassifier(),\n",
    "        \"params\": {\n",
    "            \"hidden_layer_sizes\": [(50, 50), (100, 50), (100, 100)],\n",
    "            \"alpha\": [0.0001, 0.001, 0.01],\n",
    "            \"max_iter\": [1000]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc42d6ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: Logistic Regression\n",
      "Best Parameters: {'C': 1, 'penalty': 'l2'}\n",
      "Accuracy: 0.993006993006993\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        53\n",
      "           1       0.99      1.00      0.99        90\n",
      "\n",
      "    accuracy                           0.99       143\n",
      "   macro avg       0.99      0.99      0.99       143\n",
      "weighted avg       0.99      0.99      0.99       143\n",
      "\n",
      "==================================================\n",
      "Classifier: Support Vector Machine\n",
      "Best Parameters: {'C': 0.1, 'kernel': 'linear'}\n",
      "Accuracy: 0.9790209790209791\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        53\n",
      "           1       0.97      1.00      0.98        90\n",
      "\n",
      "    accuracy                           0.98       143\n",
      "   macro avg       0.98      0.97      0.98       143\n",
      "weighted avg       0.98      0.98      0.98       143\n",
      "\n",
      "==================================================\n",
      "Classifier: Naive Bayes\n",
      "Best Parameters: {}\n",
      "Accuracy: 0.9230769230769231\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.89      0.90        53\n",
      "           1       0.93      0.94      0.94        90\n",
      "\n",
      "    accuracy                           0.92       143\n",
      "   macro avg       0.92      0.92      0.92       143\n",
      "weighted avg       0.92      0.92      0.92       143\n",
      "\n",
      "==================================================\n",
      "Classifier: Random Forest\n",
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Accuracy: 0.958041958041958\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        53\n",
      "           1       0.97      0.97      0.97        90\n",
      "\n",
      "    accuracy                           0.96       143\n",
      "   macro avg       0.96      0.96      0.96       143\n",
      "weighted avg       0.96      0.96      0.96       143\n",
      "\n",
      "==================================================\n",
      "Classifier: Gradient Boosting\n",
      "Best Parameters: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "Accuracy: 0.9370629370629371\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.91        53\n",
      "           1       0.95      0.96      0.95        90\n",
      "\n",
      "    accuracy                           0.94       143\n",
      "   macro avg       0.93      0.93      0.93       143\n",
      "weighted avg       0.94      0.94      0.94       143\n",
      "\n",
      "==================================================\n",
      "Classifier: Decision Tree\n",
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 5}\n",
      "Accuracy: 0.8741258741258742\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.89      0.84        53\n",
      "           1       0.93      0.87      0.90        90\n",
      "\n",
      "    accuracy                           0.87       143\n",
      "   macro avg       0.86      0.88      0.87       143\n",
      "weighted avg       0.88      0.87      0.88       143\n",
      "\n",
      "==================================================\n",
      "Classifier: Neural Network (MLP)\n",
      "Best Parameters: {'alpha': 0.0001, 'hidden_layer_sizes': (100, 50), 'max_iter': 1000}\n",
      "Accuracy: 0.972027972027972\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96        53\n",
      "           1       0.98      0.98      0.98        90\n",
      "\n",
      "    accuracy                           0.97       143\n",
      "   macro avg       0.97      0.97      0.97       143\n",
      "weighted avg       0.97      0.97      0.97       143\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "best_params_list = []\n",
    "# Perform hyperparameter tuning and evaluation for each classifier\n",
    "for name, clf_info in classifiers.items():\n",
    "    model = clf_info[\"model\"]\n",
    "    params = clf_info[\"params\"]\n",
    "\n",
    "    grid_search = GridSearchCV(model, params, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    # Make predictions with the best model\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    # Evaluate the model and store results\n",
    "    accuracy, confusionmat, report = evaluate_model(y_test, y_pred)\n",
    "    \n",
    "    # Append best params and accuracy to lists\n",
    "    best_params_list.append((name, best_params))\n",
    "    accuracy_list.append((name, accuracy))\n",
    "\n",
    "    print(f\"Classifier: {name}\")\n",
    "    print(f\"Best Parameters: {best_params}\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(report)\n",
    "    print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "53a25f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for Each Classifier:\n",
      "Classifier: Logistic Regression\n",
      "Best Parameters: {'C': 1, 'penalty': 'l2'}\n",
      "==================================================\n",
      "Classifier: Support Vector Machine\n",
      "Best Parameters: {'C': 0.1, 'kernel': 'linear'}\n",
      "==================================================\n",
      "Classifier: Naive Bayes\n",
      "Best Parameters: {}\n",
      "==================================================\n",
      "Classifier: Random Forest\n",
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "==================================================\n",
      "Classifier: Gradient Boosting\n",
      "Best Parameters: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "==================================================\n",
      "Classifier: Decision Tree\n",
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 5}\n",
      "==================================================\n",
      "Classifier: Neural Network (MLP)\n",
      "Best Parameters: {'alpha': 0.0001, 'hidden_layer_sizes': (100, 50), 'max_iter': 1000}\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Print the best parameters and accuracy for each classifier\n",
    "print(\"Best Parameters for Each Classifier:\")\n",
    "for name, best_params in best_params_list:\n",
    "    print(f\"Classifier: {name}\")\n",
    "    print(f\"Best Parameters: {best_params}\")\n",
    "    print(\"=\" * 50)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 ('new_venvv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "6d3fd942242e54f0da206bbce58b72555f85ec3de977aeac95dc0001629f7dbf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
